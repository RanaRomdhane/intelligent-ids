{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation for Intrusion Detection System\n",
        "\n",
        "This notebook provides detailed evaluation metrics, confusion matrices, and performance analysis for trained IDS models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
        "\n",
        "from src.preprocessing import DataPreprocessor\n",
        "from src.models import RandomForestIDS, SVMIDS, NeuralNetworkIDS\n",
        "from src.evaluation import ModelEvaluator\n",
        "from src.visualization import IDSVisualizer\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Models and Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessor\n",
        "preprocessor = DataPreprocessor()\n",
        "preprocessor.load_preprocessor('../models/preprocessor.pkl')\n",
        "\n",
        "# Load test data\n",
        "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
        "y_test = pd.read_csv('../data/processed/y_test.csv').values.ravel()\n",
        "\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of test samples: {len(y_test)}\")\n",
        "\n",
        "# Get class names\n",
        "class_names = preprocessor.label_encoder.classes_ if hasattr(preprocessor.label_encoder, 'classes_') else None\n",
        "print(f\"Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Evaluate Random Forest Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "rf_model = RandomForestIDS()\n",
        "rf_model.load('../models/random_forest_model.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_proba_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "# Evaluate\n",
        "rf_evaluator = ModelEvaluator(\"Random Forest\")\n",
        "rf_metrics = rf_evaluator.evaluate(y_test, y_pred_rf, y_proba_rf)\n",
        "rf_evaluator.confusion_matrix(y_test, y_pred_rf, class_names=class_names)\n",
        "\n",
        "# ROC curve (for binary classification)\n",
        "if len(np.unique(y_test)) == 2:\n",
        "    rf_evaluator.roc_curve(y_test, y_proba_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Evaluate SVM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "svm_model = SVMIDS()\n",
        "svm_model.load('../models/svm_model.pkl')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "y_proba_svm = svm_model.predict_proba(X_test)\n",
        "\n",
        "# Evaluate\n",
        "svm_evaluator = ModelEvaluator(\"SVM\")\n",
        "svm_metrics = svm_evaluator.evaluate(y_test, y_pred_svm, y_proba_svm)\n",
        "svm_evaluator.confusion_matrix(y_test, y_pred_svm, class_names=class_names)\n",
        "\n",
        "# ROC curve (for binary classification)\n",
        "if len(np.unique(y_test)) == 2:\n",
        "    svm_evaluator.roc_curve(y_test, y_proba_svm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "nn_model = NeuralNetworkIDS()\n",
        "nn_model.load('../models/neural_network_model.h5')\n",
        "\n",
        "# Make predictions\n",
        "y_pred_nn = nn_model.predict(X_test)\n",
        "y_proba_nn = nn_model.predict_proba(X_test)\n",
        "\n",
        "# Evaluate\n",
        "nn_evaluator = ModelEvaluator(\"Neural Network\")\n",
        "nn_metrics = nn_evaluator.evaluate(y_test, y_pred_nn, y_proba_nn)\n",
        "nn_evaluator.confusion_matrix(y_test, y_pred_nn, class_names=class_names)\n",
        "\n",
        "# ROC curve (for binary classification)\n",
        "if len(np.unique(y_test)) == 2:\n",
        "    nn_evaluator.roc_curve(y_test, y_proba_nn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comprehensive Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all metrics\n",
        "all_metrics = {\n",
        "    'Random Forest': rf_metrics,\n",
        "    'SVM': svm_metrics,\n",
        "    'Neural Network': nn_metrics\n",
        "}\n",
        "\n",
        "# Create comparison\n",
        "comparison_df = pd.DataFrame(all_metrics).T\n",
        "print(\"Comprehensive Model Comparison:\")\n",
        "print(comparison_df)\n",
        "\n",
        "# Visualize\n",
        "visualizer = IDSVisualizer()\n",
        "visualizer.plot_model_performance_comparison(all_metrics)\n",
        "\n",
        "# Save results\n",
        "comparison_df.to_csv('../models/detailed_evaluation.csv')\n",
        "print(\"\\nDetailed evaluation saved to ../models/detailed_evaluation.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
