"""
Module d'int√©gration avec ELK Stack (Elasticsearch, Logstash, Kibana).
Permet l'envoi et la visualisation des alertes et logs IDS.
"""

from elasticsearch import Elasticsearch, helpers
from datetime import datetime
import json
import logging


class ELKIntegration:
    """Int√©gration avec Elasticsearch pour SIEM."""
    
    def __init__(self, hosts=['localhost:9200'], username=None, password=None):
        """
        Initialise la connexion Elasticsearch.
        
        Args:
            hosts: Liste des h√¥tes Elasticsearch
            username: Nom d'utilisateur (optionnel)
            password: Mot de passe (optionnel)
        """
        self.logger = logging.getLogger(__name__)
        
        try:
            if username and password:
                self.es = Elasticsearch(
                    hosts,
                    basic_auth=(username, password)
                )
            else:
                self.es = Elasticsearch(hosts)
            
            # V√©rifier la connexion
            if self.es.ping():
                self.logger.info("‚úì Connexion √† Elasticsearch √©tablie")
            else:
                self.logger.error("‚úó Impossible de se connecter √† Elasticsearch")
                
        except Exception as e:
            self.logger.error(f"Erreur de connexion Elasticsearch: {e}")
            self.es = None
    
    def create_indices(self):
        """Cr√©e les indices n√©cessaires dans Elasticsearch."""
        if not self.es:
            return False
        
        indices = {
            'ids-alerts': {
                'mappings': {
                    'properties': {
                        'alert_id': {'type': 'keyword'},
                        'timestamp': {'type': 'date'},
                        'alert_type': {'type': 'keyword'},
                        'severity': {'type': 'keyword'},
                        'source_ip': {'type': 'ip'},
                        'destination_ip': {'type': 'ip'},
                        'description': {'type': 'text'},
                        'confidence_score': {'type': 'float'},
                        'status': {'type': 'keyword'}
                    }
                }
            },
            'ids-traffic': {
                'mappings': {
                    'properties': {
                        'timestamp': {'type': 'date'},
                        'source_ip': {'type': 'ip'},
                        'destination_ip': {'type': 'ip'},
                        'source_port': {'type': 'integer'},
                        'destination_port': {'type': 'integer'},
                        'protocol': {'type': 'keyword'},
                        'packet_size': {'type': 'integer'},
                        'prediction': {'type': 'keyword'},
                        'confidence': {'type': 'float'}
                    }
                }
            },
            'ids-statistics': {
                'mappings': {
                    'properties': {
                        'timestamp': {'type': 'date'},
                        'total_packets': {'type': 'long'},
                        'packets_per_second': {'type': 'float'},
                        'attacks_detected': {'type': 'integer'},
                        'protocol_distribution': {'type': 'object'}
                    }
                }
            }
        }
        
        for index_name, index_body in indices.items():
            try:
                if not self.es.indices.exists(index=index_name):
                    self.es.indices.create(index=index_name, body=index_body)
                    self.logger.info(f"Index '{index_name}' cr√©√©")
                else:
                    self.logger.info(f"Index '{index_name}' existe d√©j√†")
            except Exception as e:
                self.logger.error(f"Erreur cr√©ation index {index_name}: {e}")
                return False
        
        return True
    
    def index_alert(self, alert):
        """
        Indexe une alerte dans Elasticsearch.
        
        Args:
            alert: Objet Alert √† indexer
        
        Returns:
            bool: True si succ√®s
        """
        if not self.es:
            return False
        
        try:
            alert_dict = alert.to_dict()
            
            # Convertir timestamp en format ISO
            if isinstance(alert_dict['timestamp'], str):
                alert_dict['timestamp'] = alert_dict['timestamp']
            else:
                alert_dict['timestamp'] = alert_dict['timestamp'].isoformat()
            
            # Indexer
            response = self.es.index(
                index='ids-alerts',
                document=alert_dict
            )
            
            self.logger.info(f"Alerte {alert.alert_id} index√©e dans Elasticsearch")
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur indexation alerte: {e}")
            return False
    
    def index_traffic(self, packet_data):
        """
        Indexe des donn√©es de trafic r√©seau.
        
        Args:
            packet_data: Dictionnaire contenant les donn√©es du paquet
        
        Returns:
            bool: True si succ√®s
        """
        if not self.es:
            return False
        
        try:
            # Ajouter timestamp si absent
            if 'timestamp' not in packet_data:
                packet_data['timestamp'] = datetime.now().isoformat()
            
            self.es.index(
                index='ids-traffic',
                document=packet_data
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur indexation trafic: {e}")
            return False
    
    def bulk_index_traffic(self, traffic_data_list):
        """
        Indexe en masse des donn√©es de trafic.
        
        Args:
            traffic_data_list: Liste de dictionnaires de donn√©es de trafic
        
        Returns:
            int: Nombre de documents index√©s
        """
        if not self.es or not traffic_data_list:
            return 0
        
        try:
            actions = []
            for traffic_data in traffic_data_list:
                if 'timestamp' not in traffic_data:
                    traffic_data['timestamp'] = datetime.now().isoformat()
                
                actions.append({
                    '_index': 'ids-traffic',
                    '_source': traffic_data
                })
            
            success, failed = helpers.bulk(self.es, actions)
            self.logger.info(f"{success} documents de trafic index√©s")
            
            return success
            
        except Exception as e:
            self.logger.error(f"Erreur bulk indexation: {e}")
            return 0
    
    def index_statistics(self, stats):
        """
        Indexe des statistiques syst√®me.
        
        Args:
            stats: Dictionnaire de statistiques
        
        Returns:
            bool: True si succ√®s
        """
        if not self.es:
            return False
        
        try:
            stats['timestamp'] = datetime.now().isoformat()
            
            self.es.index(
                index='ids-statistics',
                document=stats
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erreur indexation statistiques: {e}")
            return False
    
    def search_alerts(self, query=None, severity=None, start_time=None, 
                      end_time=None, size=100):
        """
        Recherche des alertes avec filtres.
        
        Args:
            query: Requ√™te de recherche
            severity: Filtrer par s√©v√©rit√©
            start_time: Date de d√©but
            end_time: Date de fin
            size: Nombre max de r√©sultats
        
        Returns:
            list: Liste des alertes trouv√©es
        """
        if not self.es:
            return []
        
        try:
            # Construire la requ√™te
            must_clauses = []
            
            if query:
                must_clauses.append({
                    'multi_match': {
                        'query': query,
                        'fields': ['description', 'alert_type']
                    }
                })
            
            if severity:
                must_clauses.append({'term': {'severity': severity}})
            
            if start_time or end_time:
                range_clause = {'range': {'timestamp': {}}}
                if start_time:
                    range_clause['range']['timestamp']['gte'] = start_time
                if end_time:
                    range_clause['range']['timestamp']['lte'] = end_time
                must_clauses.append(range_clause)
            
            search_body = {
                'query': {
                    'bool': {
                        'must': must_clauses if must_clauses else [{'match_all': {}}]
                    }
                },
                'sort': [{'timestamp': {'order': 'desc'}}],
                'size': size
            }
            
            response = self.es.search(
                index='ids-alerts',
                body=search_body
            )
            
            return [hit['_source'] for hit in response['hits']['hits']]
            
        except Exception as e:
            self.logger.error(f"Erreur recherche alertes: {e}")
            return []
    
    def get_alert_statistics(self, start_time=None, end_time=None):
        """
        Obtient des statistiques sur les alertes.
        
        Args:
            start_time: Date de d√©but
            end_time: Date de fin
        
        Returns:
            dict: Statistiques d'alertes
        """
        if not self.es:
            return {}
        
        try:
            # Construire le filtre de temps
            time_filter = []
            if start_time or end_time:
                range_filter = {'range': {'timestamp': {}}}
                if start_time:
                    range_filter['range']['timestamp']['gte'] = start_time
                if end_time:
                    range_filter['range']['timestamp']['lte'] = end_time
                time_filter.append(range_filter)
            
            # Agr√©gations
            agg_body = {
                'query': {
                    'bool': {
                        'filter': time_filter if time_filter else []
                    }
                },
                'aggs': {
                    'by_severity': {
                        'terms': {'field': 'severity'}
                    },
                    'by_type': {
                        'terms': {'field': 'alert_type'}
                    },
                    'by_status': {
                        'terms': {'field': 'status'}
                    },
                    'timeline': {
                        'date_histogram': {
                            'field': 'timestamp',
                            'calendar_interval': 'hour'
                        }
                    }
                },
                'size': 0
            }
            
            response = self.es.search(
                index='ids-alerts',
                body=agg_body
            )
            
            return {
                'total': response['hits']['total']['value'],
                'by_severity': {
                    bucket['key']: bucket['doc_count'] 
                    for bucket in response['aggregations']['by_severity']['buckets']
                },
                'by_type': {
                    bucket['key']: bucket['doc_count']
                    for bucket in response['aggregations']['by_type']['buckets']
                },
                'by_status': {
                    bucket['key']: bucket['doc_count']
                    for bucket in response['aggregations']['by_status']['buckets']
                },
                'timeline': [
                    {
                        'timestamp': bucket['key_as_string'],
                        'count': bucket['doc_count']
                    }
                    for bucket in response['aggregations']['timeline']['buckets']
                ]
            }
            
        except Exception as e:
            self.logger.error(f"Erreur statistiques alertes: {e}")
            return {}
    
    def create_kibana_dashboards(self):
        """Cr√©e des dashboards Kibana pr√©d√©finis."""
        # Configuration des dashboards Kibana
        dashboards = {
            'ids-overview': {
                'title': 'IDS Overview Dashboard',
                'description': 'Vue d\'ensemble du syst√®me IDS',
                'visualizations': [
                    'alerts-by-severity',
                    'alerts-timeline',
                    'top-attack-types',
                    'network-traffic-volume'
                ]
            }
        }
        
        self.logger.info("Configuration des dashboards Kibana √† effectuer manuellement")
        return dashboards


def setup_elk_integration():
    """Configure l'int√©gration ELK compl√®te."""
    elk = ELKIntegration(
        hosts=['localhost:9200'],
        # username='elastic',
        # password='your_password'
    )
    
    if elk.es:
        print("‚úì Connexion √† Elasticsearch √©tablie")
        
        # Cr√©er les indices
        if elk.create_indices():
            print("‚úì Indices cr√©√©s avec succ√®s")
        
        # Afficher la configuration Kibana
        dashboards = elk.create_kibana_dashboards()
        print("\nüìä Dashboards Kibana sugg√©r√©s:")
        for name, config in dashboards.items():
            print(f"  - {config['title']}")
        
        return elk
    else:
        print("‚úó √âchec de connexion √† Elasticsearch")
        return None


if __name__ == "__main__":
    # Test de l'int√©gration
    elk = setup_elk_integration()
    
    if elk:
        # Tester l'indexation
        test_alert = {
            'alert_id': 'TEST-001',
            'timestamp': datetime.now().isoformat(),
            'alert_type': 'DoS',
            'severity': 'high',
            'source_ip': '192.168.1.100',
            'destination_ip': '10.0.0.1',
            'description': 'Test alert',
            'confidence_score': 0.95,
            'status': 'new'
        }
        
        print("\nüß™ Test d'indexation...")
        # elk.index_alert(test_alert)
        
        print("‚úì Int√©gration ELK configur√©e")